{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_m</th>\n",
       "      <th>lang_GT_API</th>\n",
       "      <th>stopword</th>\n",
       "      <th>remove?</th>\n",
       "      <th>remove_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>hatred</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>four</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sleeve</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sleep</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>yell</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3186</td>\n",
       "      <td>at</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>nltk_sw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3187</td>\n",
       "      <td>confess</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3188</td>\n",
       "      <td>sincere</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3189</td>\n",
       "      <td>richard</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3190 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_m lang_GT_API stopword  remove? remove_class\n",
       "0      hatred          en    False    False          NaN\n",
       "1      yellow          en    False    False          NaN\n",
       "2        four          en    False    False          NaN\n",
       "3      sleeve          en    False    False          NaN\n",
       "4       sleep          en    False    False          NaN\n",
       "...       ...         ...      ...      ...          ...\n",
       "3185     yell          en    False    False          NaN\n",
       "3186       at          en      NaN     True      nltk_sw\n",
       "3187  confess          en    False    False          NaN\n",
       "3188  sincere          en    False    False          NaN\n",
       "3189  richard          en    False    False          NaN\n",
       "\n",
       "[3190 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This df contains only and all valid English words.\n",
    "\n",
    "rmls = pd.read_csv('reverse_mapping_new.csv', sep=',')\n",
    "enwords = rmls[(rmls['lang_GT_API'] == 'en') & \n",
    "               (rmls['remove_class'] != 'sign') & \n",
    "               (rmls['remove_class'] != 'letter') & \n",
    "               (rmls['remove_class'] != 'numeric')]\n",
    "# The stem column is dropped, because otherwise the getIndex function would return two positions of each word.\n",
    "enwords = enwords.drop(columns=['stem']).reset_index(drop=True)\n",
    "enwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpaCy acts weird with df-extracted strings: it only processes partial values.\n",
    "# I failed to fix it, so I take a detour and use text file.\n",
    "\n",
    "word_m = enwords[['word_m']]\n",
    "word_m.to_csv('to_be_tagged.txt', header=None, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns count: 2044\n",
      "Verbs count: 554\n",
      "Adjectives count: 335\n",
      "Adverbs count: 99\n",
      "Total count: 3032\n"
     ]
    }
   ],
   "source": [
    "# Select and categorise words-to-tag.\n",
    "\n",
    "nouns = []\n",
    "verbs = []\n",
    "adjectives = []\n",
    "adverbs = []\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = open('to_be_tagged.txt').read()\n",
    "words_to_tag = nlp(text)\n",
    "for word in words_to_tag:\n",
    "    if word.pos_ == 'NOUN' or word.pos_ == 'PROPN' or word.pos_ == 'NUM':\n",
    "        nouns.append(word)\n",
    "    if word.pos_ == 'VERB':\n",
    "        verbs.append(word)  \n",
    "    if word.pos_ == 'ADJ':\n",
    "        adjectives.append(word)\n",
    "    if word.pos_ == 'ADV':\n",
    "        adverbs.append(word)\n",
    "        \n",
    "print('Nouns count: ' + str(len(nouns)))\n",
    "print('Verbs count: ' + str(len(verbs)))\n",
    "print('Adjectives count: '+ str(len(adjectives)))\n",
    "print('Adverbs count: ' + str(len(adverbs)))\n",
    "print('Total count: ' + str((len(nouns)+len(verbs)+len(adjectives)+len(adverbs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the index of words-to-tag.\n",
    "\n",
    "def getIndex(df,value):\n",
    "    index = []\n",
    "    result = df.isin([value])\n",
    "    series_object = result.any()\n",
    "    columns = list(series_object[series_object == True].index)\n",
    "    for col in columns:\n",
    "        rows = list(result[col][result[col] == True].index)\n",
    "        for row in rows:\n",
    "            index.append(row)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag the nouns.\n",
    "\n",
    "nouns = [str(i) for i in nouns]\n",
    "n_index = {word: getIndex(enwords, word) for word in nouns}\n",
    "\n",
    "for key, value in n_index.items():\n",
    "    rowIndex = [int(i) for i in value]\n",
    "    enwords.loc[enwords.index[rowIndex], 'pos'] = 'n.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag the verbs.\n",
    "\n",
    "verbs = [str(i) for i in verbs]\n",
    "v_index = {word: getIndex(enwords, word) for word in verbs}\n",
    "\n",
    "for key, value in v_index.items():\n",
    "    rowIndex = [int(i) for i in value]\n",
    "    enwords.loc[enwords.index[rowIndex], 'pos'] = 'v.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag the adjectives.\n",
    "\n",
    "adjectives = [str(i) for i in adjectives]\n",
    "adj_index = {word: getIndex(enwords, word) for word in adjectives}\n",
    "\n",
    "for key, value in adj_index.items():\n",
    "    rowIndex = [int(i) for i in value]\n",
    "    enwords.loc[enwords.index[rowIndex], 'pos'] = 'adj.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag the adverbs.\n",
    "\n",
    "adverbs = [str(i) for i in adverbs]\n",
    "adv_index = {word: getIndex(enwords, word) for word in adverbs}\n",
    "\n",
    "for key, value in adv_index.items():\n",
    "    rowIndex = [int(i) for i in value]\n",
    "    enwords.loc[enwords.index[rowIndex], 'pos'] = 'adv.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if all words are tagged -- 31 words are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2032, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be 2044 nouns. 10 missing.\n",
    "\n",
    "enwords[(enwords['pos'] == 'n.')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be 554 verbs. 21 missing.\n",
    "\n",
    "enwords[(enwords['pos'] == 'v.')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enwords[(enwords['pos'] == 'adj.')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enwords[(enwords['pos'] == 'adv.')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spinning', 'mr', '.', 'dr', '.', 'alleluia', 'fore', 'st'], []]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing nouns: 8 shown, 2 still missing.\n",
    "\n",
    "def missingValues(a, b):\n",
    "    return [[x for x in a if x not in b],[x for x in b if x not in a]]\n",
    "\n",
    "nouns_tagged = enwords[enwords['pos']=='n.']\n",
    "nouns_tagged = nouns_tagged['word_m'].to_list()\n",
    "missingValues(nouns, nouns_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ca',\n",
       "  'gon',\n",
       "  'ca',\n",
       "  '’s',\n",
       "  'wo',\n",
       "  '’s',\n",
       "  'wo',\n",
       "  '’ll',\n",
       "  'ai',\n",
       "  've',\n",
       "  'gon',\n",
       "  'cause',\n",
       "  '’re',\n",
       "  '’m',\n",
       "  '’m',\n",
       "  'wo',\n",
       "  's',\n",
       "  '’re'],\n",
       " []]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing verbs: 18 shown, 3 still missing.\n",
    "\n",
    "verbs_tagged = enwords[enwords['pos']=='v.']\n",
    "verbs_tagged = verbs_tagged['word_m'].to_list()\n",
    "missingValues(verbs, verbs_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... So it is the puncuation that causes the mismatches. The noun/verb lists are longer (for splitting original words) than supposed to be. \n",
    "\n",
    "#### 1) I will manually add 'alleluia', 'fore' and 'cause' into the output csv file; the others seem less relevant. \n",
    "\n",
    "#### 2) How come there are still 5 missing words? I disregard them but it's confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_m</th>\n",
       "      <th>lang_GT_API</th>\n",
       "      <th>stopword</th>\n",
       "      <th>remove?</th>\n",
       "      <th>remove_class</th>\n",
       "      <th>pos</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>hatred</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "      <td>hatr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adj.</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>four</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sleeve</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "      <td>sleev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sleep</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>yell</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "      <td>yell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3186</td>\n",
       "      <td>at</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>nltk_sw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3187</td>\n",
       "      <td>confess</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "      <td>confess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3188</td>\n",
       "      <td>sincere</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adj.</td>\n",
       "      <td>sincer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3189</td>\n",
       "      <td>richard</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "      <td>richard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3190 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_m lang_GT_API stopword  remove? remove_class   pos     stem\n",
       "0      hatred          en    False    False          NaN    n.     hatr\n",
       "1      yellow          en    False    False          NaN  adj.   yellow\n",
       "2        four          en    False    False          NaN    n.     four\n",
       "3      sleeve          en    False    False          NaN    n.    sleev\n",
       "4       sleep          en    False    False          NaN    n.    sleep\n",
       "...       ...         ...      ...      ...          ...   ...      ...\n",
       "3185     yell          en    False    False          NaN    n.     yell\n",
       "3186       at          en      NaN     True      nltk_sw   NaN       at\n",
       "3187  confess          en    False    False          NaN    n.  confess\n",
       "3188  sincere          en    False    False          NaN  adj.   sincer\n",
       "3189  richard          en    False    False          NaN    n.  richard\n",
       "\n",
       "[3190 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the previously deleted 'stem' to DF\n",
    "\n",
    "rmls = pd.read_csv('reverse_mapping_new.csv', sep=',')\n",
    "enwords_fix = rmls[(rmls['lang_GT_API'] == 'en') & \n",
    "                   (rmls['remove_class'] != 'sign') & \n",
    "                   (rmls['remove_class'] != 'letter') & \n",
    "                   (rmls['remove_class'] != 'numeric')]\n",
    "enwords['stem'] = enwords_fix[['stem']].reset_index(drop=True)\n",
    "enwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem</th>\n",
       "      <th>word_m</th>\n",
       "      <th>lang_GT_API</th>\n",
       "      <th>stopword</th>\n",
       "      <th>remove?</th>\n",
       "      <th>remove_class</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>hatr</td>\n",
       "      <td>hatred</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>four</td>\n",
       "      <td>four</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sleev</td>\n",
       "      <td>sleeve</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>yell</td>\n",
       "      <td>yell</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3186</td>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>nltk_sw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3187</td>\n",
       "      <td>confess</td>\n",
       "      <td>confess</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3188</td>\n",
       "      <td>sincer</td>\n",
       "      <td>sincere</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3189</td>\n",
       "      <td>richard</td>\n",
       "      <td>richard</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3190 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stem   word_m lang_GT_API stopword  remove? remove_class   pos\n",
       "0        hatr   hatred          en    False    False          NaN    n.\n",
       "1      yellow   yellow          en    False    False          NaN  adj.\n",
       "2        four     four          en    False    False          NaN    n.\n",
       "3       sleev   sleeve          en    False    False          NaN    n.\n",
       "4       sleep    sleep          en    False    False          NaN    n.\n",
       "...       ...      ...         ...      ...      ...          ...   ...\n",
       "3185     yell     yell          en    False    False          NaN    n.\n",
       "3186       at       at          en      NaN     True      nltk_sw   NaN\n",
       "3187  confess  confess          en    False    False          NaN    n.\n",
       "3188   sincer  sincere          en    False    False          NaN  adj.\n",
       "3189  richard  richard          en    False    False          NaN    n.\n",
       "\n",
       "[3190 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .insert() doesn't take series as value. Error: “Series objects are mutable and cannot be hashed”\n",
    "# Although pandas 1.0.1 documentation says it CAN take series as value. \n",
    "# Anyway, I didn't figure out why, but take a detour.\n",
    "\n",
    "cols = enwords.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "enwords = enwords[cols]\n",
    "enwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "enwords.to_csv('wordlist_pos.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
